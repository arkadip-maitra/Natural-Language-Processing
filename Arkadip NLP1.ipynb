{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  (159571, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('toxic_data.csv')\n",
    "print('Shape of the data: ', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_multilabel count:  159571\n"
     ]
    }
   ],
   "source": [
    "y_cols = list(data.columns[2:])\n",
    "is_multilabel = (data[y_cols].sum(axis=1) >1).count()\n",
    "print('is_multilabel count: ', is_multilabel)\n",
    "\n",
    "data['non_toxic'] = 1-data[y_cols].max(axis=1)\n",
    "y_cols += ['non_toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (107709,) \n",
      "y_train shape (107709, 7) \n",
      "X_test shape (15958,) \n",
      "y_test shape (15958, 7) \n",
      "X_val shape (35904,) \n",
      "y_val shape (35904, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_train_test_val(data):\n",
    "    X_data = data['comment_text'].values\n",
    "    y_data = data[list(data.columns[2:])].values\n",
    "    X, X_test, y, y_test = train_test_split(X_data, y_data, test_size=0.1, train_size=0.9)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.25,train_size =0.75)\n",
    "\n",
    "    print(\n",
    "        'X_train shape', X_train.shape,\n",
    "        '\\ny_train shape', y_train.shape,\n",
    "        '\\nX_test shape', X_test.shape,\n",
    "        '\\ny_test shape', y_test.shape,\n",
    "        '\\nX_val shape', X_val.shape,\n",
    "        '\\ny_val shape', y_val.shape,\n",
    "\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_train_test_val(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, I got it. Thanks.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def label_encoder(array):\n",
    "    rows, cols = array.shape\n",
    "    label = np.zeros(rows)\n",
    "    rows, cols = array.shape\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if(array[i][j] == 1):\n",
    "                label[i] = j\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = label_encoder(y_train)\n",
    "y_val = label_encoder(y_val)\n",
    "y_test = label_encoder(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sysadm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sysadm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ketuanan melayu never mentioned constitution mentions hak keistimewaan orang melayu nothing mentioned aborigin rights like countries like canada singapore ketuanan melayu invented im sure exactly first used one may say derivation article 153 gone far beneficial abused used tool barisan nasional gain rationale behind hak keistimewaan orang melayu claimed malays aborigins although dont really agree peranakans settled malacca 15th centuries true aborigins none orang aslis lets assume fact malays aborigins true article 153 never introduced malays first policy rather means protect malay rights well rights races country article 153 never controversial rather abused certain politicians hope makes clear prominent example happens country right government scholarship read almost everywhere isnt already official discrimination read like btn courses always refers chinese include peranakan generations indians pendatang fact parameswara pendatang also khir toyo although malaysia officially enthnocracy see malaysia appears one enthocracy limited particular race government positions refers also racial policies practises definition ethnocracy includes use advance position particular ethnic group detriment others malays first policy nep mara many indeed clear without elaboration note dont agree anything people writes article please refer talk page dont vandalise article copy pasting also youre anyone confident fact theyre going write please provides citations ihope page used propaganda certain parties bn pr',\n",
       " 'stop deleting information']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "\n",
    "import re\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "REPLACE_IP_ADDRESS = re.compile(r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b')\n",
    "\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.replace('\\n', ' ').lower()# lowercase text\n",
    "    text = REPLACE_IP_ADDRESS.sub('', text) # remove ip address\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ',text)# replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('',text)# delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join([w for w in text.split() if not w in STOPWORDS])# delete stopwords from text\n",
    "    return text\n",
    "\n",
    "X_train = [text_prepare(x) for x in X_train]\n",
    "X_val = [text_prepare(x) for x in X_val]\n",
    "X_test = [text_prepare(x) for x in X_test]\n",
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "words_counts = {}\n",
    "for comments in X_train:\n",
    "    for word in comments.split():\n",
    "        if word not in words_counts:\n",
    "            words_counts[word] = 1\n",
    "        words_counts[word] += 1\n",
    "        \n",
    "DICT_SIZE = 10000 # Test with multiple values\n",
    "POPULAR_WORDS = sorted(words_counts, key=words_counts.get, reverse=True)[:DICT_SIZE]\n",
    "WORDS_TO_INDEX = {key: rank for rank, key in enumerate(POPULAR_WORDS, 0)}\n",
    "INDEX_TO_WORDS = {index:word for word, index in WORDS_TO_INDEX.items()}\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (107709, 10000) \n",
      "X_val shape  (35904, 10000) \n",
      "X_test shape  (15958, 10000)\n"
     ]
    }
   ],
   "source": [
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for word in text.split(' '):\n",
    "        if word in words_to_index:\n",
    "            result_vector[words_to_index[word]] +=1\n",
    "    return result_vector\n",
    "\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])\n",
    "print('X_train shape ', X_train_mybag.shape, '\\nX_val shape ', X_val_mybag.shape, '\\nX_test shape ', X_test_mybag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X_train_mybag, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9001225490196079\n",
      "F1-score macro:  0.1428666837261821\n",
      "F1-score micro:  0.9001225490196079\n",
      "F1-score weighted:  0.8545045696869781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_val_predicted_labels_mybag = clf.predict(X_val_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_val, y_val_predicted_labels_mybag))\n",
    "print('F1-score macro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='macro'))\n",
    "print('F1-score micro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='micro'))\n",
    "print('F1-score weighted: ', f1_score(y_val, y_val_predicted_labels_mybag, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9008647700213059\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted_labels_mybag = clf.predict(X_test_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_test_predicted_labels_mybag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=420, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state = 420)\n",
    "clf.fit(X_train_mybag, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8876726827094474\n",
      "F1-score macro:  0.3241923457275972\n",
      "F1-score micro:  0.8876726827094473\n",
      "F1-score weighted:  0.8918587799838765\n"
     ]
    }
   ],
   "source": [
    "y_val_predicted_labels_mybag = clf.predict(X_val_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_val, y_val_predicted_labels_mybag))\n",
    "print('F1-score macro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='macro'))\n",
    "print('F1-score micro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='micro'))\n",
    "print('F1-score weighted: ', f1_score(y_val, y_val_predicted_labels_mybag, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8890838450933701\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted_labels_mybag = clf.predict(X_test_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_test_predicted_labels_mybag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors = 7)\n",
    "clf.fit(X_train_mybag, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9122381907308378\n",
      "F1-score macro:  0.2507564828588634\n",
      "F1-score micro:  0.9122381907308378\n",
      "F1-score weighted:  0.8843700160458178\n"
     ]
    }
   ],
   "source": [
    "y_val_predicted_labels_mybag = clf.predict(X_val_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_val, y_val_predicted_labels_mybag))\n",
    "print('F1-score macro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='macro'))\n",
    "print('F1-score micro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='micro'))\n",
    "print('F1-score weighted: ', f1_score(y_val, y_val_predicted_labels_mybag, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9133976688808121\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted_labels_mybag = clf.predict(X_test_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_test_predicted_labels_mybag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "words_counts = {}\n",
    "for comments in X_train:\n",
    "    for word in comments.split():\n",
    "        if word not in words_counts:\n",
    "            words_counts[word] = 1\n",
    "        words_counts[word] += 1\n",
    "        \n",
    "DICT_SIZE = 5000 #Test with multiple values\n",
    "POPULAR_WORDS = sorted(words_counts, key=words_counts.get, reverse=True)[:DICT_SIZE]\n",
    "WORDS_TO_INDEX = {key: rank for rank, key in enumerate(POPULAR_WORDS, 0)}\n",
    "INDEX_TO_WORDS = {index:word for word, index in WORDS_TO_INDEX.items()}\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (107709, 5000) \n",
      "X_val shape  (35904, 5000) \n",
      "X_test shape  (15958, 5000)\n"
     ]
    }
   ],
   "source": [
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for word in text.split(' '):\n",
    "        if word in words_to_index:\n",
    "            result_vector[words_to_index[word]] +=1\n",
    "    return result_vector\n",
    "\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])\n",
    "print('X_train shape ', X_train_mybag.shape, '\\nX_val shape ', X_val_mybag.shape, '\\nX_test shape ', X_test_mybag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9019050802139037\n",
      "F1-score macro:  0.15328861357286658\n",
      "F1-score micro:  0.9019050802139037\n",
      "F1-score weighted:  0.858769002837596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X_train_mybag, y_train)\n",
    "\n",
    "y_val_predicted_labels_mybag = clf.predict(X_val_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_val, y_val_predicted_labels_mybag))\n",
    "print('F1-score macro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='macro'))\n",
    "print('F1-score micro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='micro'))\n",
    "print('F1-score weighted: ', f1_score(y_val, y_val_predicted_labels_mybag, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9028073693445294\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted_labels_mybag = clf.predict(X_test_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_test_predicted_labels_mybag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8814338235294118\n",
      "F1-score macro:  0.3247828240220447\n",
      "F1-score micro:  0.8814338235294117\n",
      "F1-score weighted:  0.8874982497325395\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 420)\n",
    "clf.fit(X_train_mybag, y_train)\n",
    "\n",
    "y_val_predicted_labels_mybag = clf.predict(X_val_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_val, y_val_predicted_labels_mybag))\n",
    "print('F1-score macro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='macro'))\n",
    "print('F1-score micro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='micro'))\n",
    "print('F1-score weighted: ', f1_score(y_val, y_val_predicted_labels_mybag, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8840706855495676\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted_labels_mybag = clf.predict(X_test_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_test_predicted_labels_mybag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9119875222816399\n",
      "F1-score macro:  0.25615620836028585\n",
      "F1-score micro:  0.9119875222816399\n",
      "F1-score weighted:  0.8849256340804693\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 7)\n",
    "clf.fit(X_train_mybag, y_train)\n",
    "\n",
    "y_val_predicted_labels_mybag = clf.predict(X_val_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_val, y_val_predicted_labels_mybag))\n",
    "print('F1-score macro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='macro'))\n",
    "print('F1-score micro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='micro'))\n",
    "print('F1-score weighted: ', f1_score(y_val, y_val_predicted_labels_mybag, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.913147010903622\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted_labels_mybag = clf.predict(X_test_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_test_predicted_labels_mybag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse\n",
    "\n",
    "words_counts = {}\n",
    "for comments in X_train:\n",
    "    for word in comments.split():\n",
    "        if word not in words_counts:\n",
    "            words_counts[word] = 1\n",
    "        words_counts[word] += 1\n",
    "        \n",
    "DICT_SIZE = 15000 #Test with multiple values\n",
    "POPULAR_WORDS = sorted(words_counts, key=words_counts.get, reverse=True)[:DICT_SIZE]\n",
    "WORDS_TO_INDEX = {key: rank for rank, key in enumerate(POPULAR_WORDS, 0)}\n",
    "INDEX_TO_WORDS = {index:word for word, index in WORDS_TO_INDEX.items()}\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (107709, 15000) \n",
      "X_val shape  (35904, 15000) \n",
      "X_test shape  (15958, 15000)\n"
     ]
    }
   ],
   "source": [
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for word in text.split(' '):\n",
    "        if word in words_to_index:\n",
    "            result_vector[words_to_index[word]] +=1\n",
    "    return result_vector\n",
    "\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])\n",
    "print('X_train shape ', X_train_mybag.shape, '\\nX_val shape ', X_val_mybag.shape, '\\nX_test shape ', X_test_mybag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8998440285204992\n",
      "F1-score macro:  0.14056989255594243\n",
      "F1-score micro:  0.8998440285204992\n",
      "F1-score weighted:  0.8536176850951761\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X_train_mybag, y_train)\n",
    "\n",
    "y_val_predicted_labels_mybag = clf.predict(X_val_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_val, y_val_predicted_labels_mybag))\n",
    "print('F1-score macro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='macro'))\n",
    "print('F1-score micro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='micro'))\n",
    "print('F1-score weighted: ', f1_score(y_val, y_val_predicted_labels_mybag, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9006767765384134\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted_labels_mybag = clf.predict(X_test_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_test_predicted_labels_mybag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8919618983957219\n",
      "F1-score macro:  0.34455099573133285\n",
      "F1-score micro:  0.8919618983957219\n",
      "F1-score weighted:  0.8950971644847524\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 420)\n",
    "clf.fit(X_train_mybag, y_train)\n",
    "\n",
    "y_val_predicted_labels_mybag = clf.predict(X_val_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_val, y_val_predicted_labels_mybag))\n",
    "print('F1-score macro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='macro'))\n",
    "print('F1-score micro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='micro'))\n",
    "print('F1-score weighted: ', f1_score(y_val, y_val_predicted_labels_mybag, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.890023812507833\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted_labels_mybag = clf.predict(X_test_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_test_predicted_labels_mybag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9117368538324421\n",
      "F1-score macro:  0.25425470020795093\n",
      "F1-score micro:  0.9117368538324421\n",
      "F1-score weighted:  0.8837380749470691\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 7)\n",
    "clf.fit(X_train_mybag, y_train)\n",
    "\n",
    "y_val_predicted_labels_mybag = clf.predict(X_val_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_val, y_val_predicted_labels_mybag))\n",
    "print('F1-score macro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='macro'))\n",
    "print('F1-score micro: ', f1_score(y_val, y_val_predicted_labels_mybag, average='micro'))\n",
    "print('F1-score weighted: ', f1_score(y_val, y_val_predicted_labels_mybag, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9140243138237875\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted_labels_mybag = clf.predict(X_test_mybag)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_test_predicted_labels_mybag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-----------------------+-----------------+\n",
      "| Classifier   |   Dictionary Size | Validation Accuracy   | Test Accuracy   |\n",
      "+==============+===================+=======================+=================+\n",
      "| SVM          |             10000 | 90 %                  | 90 %            |\n",
      "+--------------+-------------------+-----------------------+-----------------+\n",
      "| DT           |             10000 | 88 %                  | 88 %            |\n",
      "+--------------+-------------------+-----------------------+-----------------+\n",
      "| KNN          |             10000 | 91 %                  | 91 %            |\n",
      "+--------------+-------------------+-----------------------+-----------------+\n",
      "| SVM          |              5000 | 90 %                  | 90 %            |\n",
      "+--------------+-------------------+-----------------------+-----------------+\n",
      "| DT           |              5000 | 88 %                  | 88 %            |\n",
      "+--------------+-------------------+-----------------------+-----------------+\n",
      "| KNN          |              5000 | 91 %                  | 91 %            |\n",
      "+--------------+-------------------+-----------------------+-----------------+\n",
      "| SVM          |             15000 | 89 %                  | 90 %            |\n",
      "+--------------+-------------------+-----------------------+-----------------+\n",
      "| DT           |             15000 | 88 %                  | 88 %            |\n",
      "+--------------+-------------------+-----------------------+-----------------+\n",
      "| KNN          |             15000 | 91 %                  | 91 %            |\n",
      "+--------------+-------------------+-----------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    " \n",
    "# assign data\n",
    "mydata = [\n",
    "    [\"SVM\", \"10000\", \"90 %\", \"90 %\"],\n",
    "    [\"DT\", \"10000\", \"88 %\", \"88 %\"],\n",
    "    [\"KNN\", \"10000\", \"91 %\", \"91 %\"],\n",
    "    [\"SVM\", \"5000\", \"90 %\", \"90 %\"],\n",
    "    [\"DT\", \"5000\", \"88 %\", \"88 %\"],\n",
    "    [\"KNN\", \"5000\", \"91 %\", \"91 %\"],\n",
    "    [\"SVM\", \"15000\", \"89 %\", \"90 %\"],\n",
    "    [\"DT\", \"15000\", \"88 %\", \"88 %\"],\n",
    "    [\"KNN\", \"15000\", \"91 %\", \"91 %\"]\n",
    "]\n",
    " \n",
    "# create header\n",
    "head = [\"Classifier\", \"Dictionary Size\", \"Validation Accuracy\", \"Test Accuracy\"]\n",
    " \n",
    "# display table\n",
    "print(tabulate(mydata, headers=head, tablefmt=\"grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
